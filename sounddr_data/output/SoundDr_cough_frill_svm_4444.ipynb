{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook to keep a benchmarking result of Table 7 on Covid-19 and Abnormal Detection task:\n",
    "\n",
    "+ Use Sound-Dr dataset ```dataset_type='SoundDr'```:\n",
    "+ Use FRILL pretrain model to extract Feature ```PRETRAIN=\"FRILL\"```\n",
    "+ Use SVM method to classify\n",
    "+ Set seed 4444 ```seed=4444```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoX could not be found!\n",
      "\n",
      "    If you do not have SoX, proceed here:\n",
      "     - - - http://sox.sourceforge.net/ - - -\n",
      "\n",
      "    If you do (or think that you should) have SoX, double-check your\n",
      "    path variables.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from glob import glob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os, time, math, random, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile, pickle, h5py, joblib, json\n",
    "import multiprocessing\n",
    "\n",
    "import librosa\n",
    "import opensmile\n",
    "import xgboost as xgb\n",
    "\n",
    "from math import pi\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from scipy.fftpack import fft, hilbert\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, auc, precision_recall_curve, roc_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_choice</th>\n",
       "      <th>age_choice</th>\n",
       "      <th>current_city</th>\n",
       "      <th>symptoms_status_choice</th>\n",
       "      <th>medical_condition_choice</th>\n",
       "      <th>insomnia_status_choice</th>\n",
       "      <th>smoke_status_choice</th>\n",
       "      <th>cov19_status_choice</th>\n",
       "      <th>hospital_choice</th>\n",
       "      <th>cough_noise</th>\n",
       "      <th>device_model</th>\n",
       "      <th>file_cough</th>\n",
       "      <th>label</th>\n",
       "      <th>cough_duration</th>\n",
       "      <th>nose_duration</th>\n",
       "      <th>mouth_duration</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label_symptom</th>\n",
       "      <th>label_abnormal</th>\n",
       "      <th>label_covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>thanh hóa</td>\n",
       "      <td>['No']</td>\n",
       "      <td>['No']</td>\n",
       "      <td>No</td>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "      <td>No</td>\n",
       "      <td>True</td>\n",
       "      <td>OPPO CPH1933</td>\n",
       "      <td>cough/good_cough_2021-08-15T13:43:33.132Z</td>\n",
       "      <td>0</td>\n",
       "      <td>25.856000</td>\n",
       "      <td>17.664000</td>\n",
       "      <td>22.357333</td>\n",
       "      <td>cough/good_cough_2021-08-15T13:43:33.132Z.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>Ho Chi Minh</td>\n",
       "      <td>['fever', 'headache']</td>\n",
       "      <td>['No']</td>\n",
       "      <td>No</td>\n",
       "      <td>never</td>\n",
       "      <td>last14</td>\n",
       "      <td>No</td>\n",
       "      <td>True</td>\n",
       "      <td>Laptop/Desktop</td>\n",
       "      <td>cough/bad_cough_2021-09-16T07:18:48.594Z</td>\n",
       "      <td>1</td>\n",
       "      <td>29.350042</td>\n",
       "      <td>29.814438</td>\n",
       "      <td>29.814438</td>\n",
       "      <td>cough/bad_cough_2021-09-16T07:18:48.594Z.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>Ho Chi Minh</td>\n",
       "      <td>['fever', 'chills', 'sorethroat', 'drycough', ...</td>\n",
       "      <td>['No']</td>\n",
       "      <td>1</td>\n",
       "      <td>1to10</td>\n",
       "      <td>last14</td>\n",
       "      <td>No</td>\n",
       "      <td>True</td>\n",
       "      <td>Laptop/Desktop</td>\n",
       "      <td>cough/bad_cough_2021-09-06T11:04:49.842Z</td>\n",
       "      <td>1</td>\n",
       "      <td>18.432000</td>\n",
       "      <td>17.152000</td>\n",
       "      <td>15.530667</td>\n",
       "      <td>cough/bad_cough_2021-09-06T11:04:49.842Z.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Ho Chi Minh</td>\n",
       "      <td>['wetcough', 'sorethroat']</td>\n",
       "      <td>['No']</td>\n",
       "      <td>No</td>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Laptop/Desktop</td>\n",
       "      <td>cough/bad_cough_2021-08-24T08:08:28.798Z</td>\n",
       "      <td>1</td>\n",
       "      <td>17.322667</td>\n",
       "      <td>17.749333</td>\n",
       "      <td>18.517333</td>\n",
       "      <td>cough/bad_cough_2021-08-24T08:08:28.798Z.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>Ho Chi Minh</td>\n",
       "      <td>['No']</td>\n",
       "      <td>['No']</td>\n",
       "      <td>No</td>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "      <td>No</td>\n",
       "      <td>True</td>\n",
       "      <td>iPhone 8</td>\n",
       "      <td>cough/good_cough_2021-09-24T06:33:54.423Z</td>\n",
       "      <td>0</td>\n",
       "      <td>21.504000</td>\n",
       "      <td>26.624000</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>cough/good_cough_2021-09-24T06:33:54.423Z.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex_choice  age_choice current_city  \\\n",
       "1305     Female          20    thanh hóa   \n",
       "1306       Male          32  Ho Chi Minh   \n",
       "1307       Male          23  Ho Chi Minh   \n",
       "1308       Male          18  Ho Chi Minh   \n",
       "1309     Female          28  Ho Chi Minh   \n",
       "\n",
       "                                 symptoms_status_choice  \\\n",
       "1305                                             ['No']   \n",
       "1306                              ['fever', 'headache']   \n",
       "1307  ['fever', 'chills', 'sorethroat', 'drycough', ...   \n",
       "1308                         ['wetcough', 'sorethroat']   \n",
       "1309                                             ['No']   \n",
       "\n",
       "     medical_condition_choice insomnia_status_choice smoke_status_choice  \\\n",
       "1305                   ['No']                     No               never   \n",
       "1306                   ['No']                     No               never   \n",
       "1307                   ['No']                      1               1to10   \n",
       "1308                   ['No']                     No               never   \n",
       "1309                   ['No']                     No               never   \n",
       "\n",
       "     cov19_status_choice hospital_choice  cough_noise    device_model  \\\n",
       "1305               never              No         True    OPPO CPH1933   \n",
       "1306              last14              No         True  Laptop/Desktop   \n",
       "1307              last14              No         True  Laptop/Desktop   \n",
       "1308               never             NaN         True  Laptop/Desktop   \n",
       "1309               never              No         True        iPhone 8   \n",
       "\n",
       "                                     file_cough  label  cough_duration  \\\n",
       "1305  cough/good_cough_2021-08-15T13:43:33.132Z      0       25.856000   \n",
       "1306   cough/bad_cough_2021-09-16T07:18:48.594Z      1       29.350042   \n",
       "1307   cough/bad_cough_2021-09-06T11:04:49.842Z      1       18.432000   \n",
       "1308   cough/bad_cough_2021-08-24T08:08:28.798Z      1       17.322667   \n",
       "1309  cough/good_cough_2021-09-24T06:33:54.423Z      0       21.504000   \n",
       "\n",
       "      nose_duration  mouth_duration  \\\n",
       "1305      17.664000       22.357333   \n",
       "1306      29.814438       29.814438   \n",
       "1307      17.152000       15.530667   \n",
       "1308      17.749333       18.517333   \n",
       "1309      26.624000       25.600000   \n",
       "\n",
       "                                          file_path  label_symptom  \\\n",
       "1305  cough/good_cough_2021-08-15T13:43:33.132Z.wav              0   \n",
       "1306   cough/bad_cough_2021-09-16T07:18:48.594Z.wav              1   \n",
       "1307   cough/bad_cough_2021-09-06T11:04:49.842Z.wav              1   \n",
       "1308   cough/bad_cough_2021-08-24T08:08:28.798Z.wav              1   \n",
       "1309  cough/good_cough_2021-09-24T06:33:54.423Z.wav              0   \n",
       "\n",
       "      label_abnormal  label_covid  \n",
       "1305               0            0  \n",
       "1306               1            1  \n",
       "1307               1            1  \n",
       "1308               1            0  \n",
       "1309               0            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample rate\n",
    "SR = 44100\n",
    "#100 ms\n",
    "FRAME_LEN = int(SR / 10)\n",
    "#50% overlap, meaning 5ms hop length\n",
    "HOP = int(FRAME_LEN / 2)\n",
    "#the MFCC dimension\n",
    "MFCC_dim = 13\n",
    "PRETRAIN = 'FRILL'\n",
    "codebook_size = 1000\n",
    "\n",
    "fold_num = 5\n",
    "seed = 4444\n",
    "\n",
    "dataset_type = 'SoundDr'\n",
    "\n",
    "if dataset_type == 'SoundDr':\n",
    "    PERIOD = 15\n",
    "    SR = 48000\n",
    "    DIR_DATA = \"./sounddr_data/\"\n",
    "\n",
    "    df = pd.read_csv(DIR_DATA + 'data.csv')\n",
    "    df['file_path'] = df['file_cough'] + '.wav'\n",
    "\n",
    "    df['label_symptom'] = (df['symptoms_status_choice'].map(str) != \"['No']\").astype(int)\n",
    "    df['label_abnormal'] = ((df['symptoms_status_choice'].map(str) != \"['No']\") | (df['cov19_status_choice'] != 'never')).astype(int)\n",
    "    df['label_covid'] = (df['cov19_status_choice'] != 'never').astype(int)\n",
    "elif dataset_type == 'CoughVid':\n",
    "    PERIOD = 10\n",
    "    SR = 22050\n",
    "\n",
    "    DIR_DATA = './coughvid_data/'\n",
    "\n",
    "    VidData   = pd.read_csv(os.path.join(DIR_DATA, 'public_dataset/metadata_compiled.csv'), header=0)\n",
    "    VidData   = VidData.loc[VidData['cough_detected'] >= 0.9][['uuid','fever_muscle_pain','respiratory_condition','status', 'quality_1', 'age', 'gender']]\n",
    "    VidData.dropna(subset=['uuid','fever_muscle_pain','respiratory_condition','status'], inplace=True)\n",
    "    VidData = VidData[(VidData['quality_1'] != 'no_cough') & (VidData['quality_1'] != 'poor')]\n",
    "    VidData = VidData[(VidData['status'] != 'symptomatic') & (VidData['status'].notna())]\n",
    "    VidData['label_covid'] = (VidData['status'] == 'COVID-19').astype(int)\n",
    "\n",
    "    extradata = VidData.loc[VidData['status']=='COVID-19']\n",
    "    notradata = VidData.loc[VidData['status']!='COVID-19']\n",
    "\n",
    "    df = pd.concat([extradata, notradata], ignore_index= True)\n",
    "    df['file_path'] = df['uuid'].apply(lambda x: 'public_dataset/' + x + '.webm')\n",
    "    def g(x):\n",
    "        for i in x:\n",
    "            if i is True:\n",
    "                return 1\n",
    "        return 0\n",
    "    df['label_abnormal'] = df[['fever_muscle_pain', 'respiratory_condition', 'label_covid']].apply(lambda x: g(x), axis=1)\n",
    "else:\n",
    "    PERIOD = 5\n",
    "    SR = 44100\n",
    "    DIR_DATA = \"./coswara_data/\"\n",
    "\n",
    "    join_by = pd.read_csv(os.path.join(DIR_DATA, 'combined_data.csv'))\n",
    "    df_list = []\n",
    "    for each in os.listdir(DIR_DATA):\n",
    "        for path in tqdm(glob(DIR_DATA + each + '/*/cough-shallow.wav')):\n",
    "            temp = pd.DataFrame(columns=['id', 'DIR'])\n",
    "            temp['id'] = [path.split('/')[-2]]\n",
    "            temp['DIR'] = [path]\n",
    "            temp = pd.merge(left=temp,right=join_by,on='id',how='inner')\n",
    "\n",
    "            temp['label_cough'] = (temp['cough'] == True).astype(int)\n",
    "\n",
    "            temp['file_path'] = each + '/' + temp['id'] + '/cough-shallow.wav'\n",
    "            temp['label_covid'] = temp['covid_status'].apply(lambda x: 1 if x == 'positive_mild' or x =='positive_moderate' or x == 'COVID-19' else 0)\n",
    "            df_list.append(temp)\n",
    "    df = pd.concat(df_list)\n",
    "    def g(x):\n",
    "        for i in x:\n",
    "            if i is True:\n",
    "                return 1\n",
    "        return 0\n",
    "    df['label_abnormal'] = df[['st', 'bd', 'cld', 'pneumonia', 'others_resp', 'asthma', 'label_covid']].apply(lambda x: g(x), axis=1)\n",
    "\n",
    "target_col = 'label_abnormal'\n",
    "OUTPUT_DIR = DIR_DATA + 'output/' + str(seed) + '/'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_duration(filename, mono=True, res_type=\"kaiser_fast\"):\n",
    "    duration = 0\n",
    "    sr = SR\n",
    "    try:\n",
    "        y, sr = librosa.load(filename, sr=None, mono=mono, res_type=res_type)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "    except:\n",
    "        print('Error file:' + filename)\n",
    "    return duration, sr\n",
    "\n",
    "df['Duration'] = df['file_path'].apply(lambda x: get_duration(os.path.join(DIR_DATA, x))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1310.000000\n",
       "mean       23.165313\n",
       "std         4.148056\n",
       "min        15.274667\n",
       "25%        19.370667\n",
       "50%        23.722667\n",
       "75%        26.538667\n",
       "max        37.546667\n",
       "Name: Duration, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    825\n",
       "1    485\n",
       "Name: label_abnormal, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[target_col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def crop_or_pad(y, length):\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, np.zeros(length-len(y))])\n",
    "    elif len(y) > length:\n",
    "        cut = random.randint(0, len(y) - length)\n",
    "        y = y[cut:cut+length]\n",
    "    return y\n",
    "\n",
    "def merge_feature(list_features):\n",
    "    \"\"\"\n",
    "      Merge numpy array features\n",
    "      Args:\n",
    "        - list_features: list of numpy array features\n",
    "                         :type: a list of numpy arrays \n",
    "      Returns:\n",
    "        - features: the concatenate numpy array along axis=1\n",
    "                    :type: a numpy array                 \n",
    "    \"\"\"      \n",
    "    features = np.concatenate(list_features, axis=1)\n",
    "    features = np.nan_to_num(features)\n",
    "    features = np.clip(features, -np.finfo(np.float32).max, np.finfo(np.float32).max)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(cfs_matrix):\n",
    "    \"\"\"\n",
    "      Calculate common metrics based on the confusion matrix\n",
    "      Args:\n",
    "        - cfs_matrix: a sklearn confusion matrix \n",
    "                      :type: a ndarray of shape (n_classes, n_classes)\n",
    "      Returns:\n",
    "        - precision: the precision of the prediction\n",
    "                     :type: float  \n",
    "        - recall: the recall of the prediction\n",
    "                  :type: float  \n",
    "        - f1: the f1-score of the prediction\n",
    "              :type: float                       \n",
    "    \"\"\"     \n",
    "    precision = cfs_matrix[1,1] / (cfs_matrix[1,1] + cfs_matrix[0,1])\n",
    "    recall = cfs_matrix[1,1] / (cfs_matrix[1,1] + cfs_matrix[1,0])\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUT_DIR + PRETRAIN + '.pickle'):\n",
    "    import tensorflow.compat.v2 as tf\n",
    "    tf.enable_v2_behavior()\n",
    "    import tensorflow_hub as hub\n",
    "\n",
    "    frill_nofrontend_model = hub.load('https://tfhub.dev/google/nonsemantic-speech-benchmark/frill-nofrontend/1')\n",
    "\n",
    "    def stabilized_log(data, additive_offset, floor):\n",
    "      \"\"\"TF version of mfcc_mel.StabilizedLog.\"\"\"\n",
    "      return tf.math.log(tf.math.maximum(data, floor) + additive_offset)\n",
    "\n",
    "\n",
    "    def log_mel_spectrogram(data,\n",
    "                            audio_sample_rate,\n",
    "                            num_mel_bins=64,\n",
    "                            log_additive_offset=0.001,\n",
    "                            log_floor=1e-12,\n",
    "                            window_length_secs=0.025,\n",
    "                            hop_length_secs=0.010,\n",
    "                            fft_length=None):\n",
    "        \"\"\"TF version of mfcc_mel.LogMelSpectrogram.\"\"\"\n",
    "        window_length_samples = int(round(audio_sample_rate * window_length_secs))\n",
    "        hop_length_samples = int(round(audio_sample_rate * hop_length_secs))\n",
    "        if not fft_length:\n",
    "            fft_length = 2 ** int(np.ceil(np.log(window_length_samples) / np.log(2.0)))\n",
    "\n",
    "        spectrogram = tf.abs(\n",
    "            tf.signal.stft(\n",
    "                tf.cast(data, tf.dtypes.float64),\n",
    "                frame_length=window_length_samples,\n",
    "                frame_step=hop_length_samples,\n",
    "                fft_length=fft_length,\n",
    "                window_fn=tf.signal.hann_window,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        to_mel = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=num_mel_bins,\n",
    "            num_spectrogram_bins=fft_length // 2 + 1,\n",
    "            sample_rate=audio_sample_rate,\n",
    "            lower_edge_hertz=125.0,\n",
    "            upper_edge_hertz=7500.0,\n",
    "            dtype=tf.dtypes.float64\n",
    "        )\n",
    "\n",
    "        mel = spectrogram @ to_mel\n",
    "        log_mel = stabilized_log(mel, log_additive_offset, log_floor)\n",
    "        return log_mel\n",
    "\n",
    "    def compute_frontend_features(samples, sr, frame_hop, n_required=16000, num_mel_bins=64, frame_width=96):\n",
    "        if samples.dtype == np.int16:\n",
    "            samples = tf.cast(samples, np.float32) / np.iinfo(np.int16).max\n",
    "        if samples.dtype == np.float64:\n",
    "            samples = tf.cast(samples, np.float32)\n",
    "        assert samples.dtype == np.float32, samples.dtype\n",
    "        n = tf.size(samples)\n",
    "        samples = tf.cond(\n",
    "            n < n_required,\n",
    "            lambda: tf.pad(samples, [(0, n_required - n)]),\n",
    "            lambda: samples\n",
    "        )\n",
    "        mel = log_mel_spectrogram(samples, sr, num_mel_bins=num_mel_bins)\n",
    "        mel = tf.signal.frame(mel, frame_length=frame_width, frame_step=frame_hop, axis=0)\n",
    "        return mel\n",
    "\n",
    "    def make_nonsemantic_frill_nofrontend_feat(filename):\n",
    "        try:\n",
    "            waveform, _ = librosa.load(os.path.join(DIR_DATA, filename), sr=16000, mono=True, res_type=\"kaiser_fast\")\n",
    "            if 2048 > waveform.shape[-1]:\n",
    "                print('File length < 2048')\n",
    "                return None, filename\n",
    "            frontend_feats = tf.expand_dims(compute_frontend_features(waveform, 16000, frame_hop=17), axis=-1).numpy().astype(np.float32)\n",
    "            assert frontend_feats.shape[1:] == (96, 64, 1)\n",
    "\n",
    "            embeddings = frill_nofrontend_model(frontend_feats)['embedding']\n",
    "            mean_emb = embeddings.numpy().mean(axis=0)\n",
    "            std_emb = embeddings.numpy().std(axis=0)\n",
    "        except Exception as e:\n",
    "            print('Error: ' + str(e))\n",
    "            return None, filename\n",
    "        return np.concatenate((mean_emb, std_emb)), filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_features_of_list_audio(df):\n",
    "    X_features = []\n",
    "    df['error'] = 0\n",
    "    for idx, r in tqdm(df.iterrows(), total=len(df)):\n",
    "        feature, filename = make_nonsemantic_frill_nofrontend_feat(r['file_path'])\n",
    "        \n",
    "        if feature is None:\n",
    "            df['error'][df['file_path'] == filename] = 1\n",
    "        else:\n",
    "            X_features.append(feature)\n",
    "    return np.array(X_features), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data feature shape: ((1310, 4096), 1310)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(OUTPUT_DIR + PRETRAIN + '.pickle'):\n",
    "    X_features, df = get_features_of_list_audio(df)\n",
    "    df.to_csv(os.path.join(OUTPUT_DIR, 'data.csv'), index=False)\n",
    "    pickle.dump({\n",
    "        'X_trill_features': X_features\n",
    "    }, open(OUTPUT_DIR + PRETRAIN + '.pickle', \"wb\" ))\n",
    "else:\n",
    "    df = pd.read_csv(os.path.join(OUTPUT_DIR, 'data.csv'))\n",
    "    f = pickle.load(open(OUTPUT_DIR + PRETRAIN + '.pickle', \"rb\" ))\n",
    "    X_features = f['X_trill_features']\n",
    "df = df[df['error'] == 0].reset_index(drop=True)\n",
    "\n",
    "# if PRETRAIN == 'OpenSmile':\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(merge_feature([X_features]))\n",
    "# else:\n",
    "#     X = merge_feature([X_features])\n",
    "print(f\"Data feature shape: {X.shape, len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(ensem_preds, targets):\n",
    "    \"\"\"\n",
    "      Evaluate the prediction by providing metrics & also the best threshold (to get the highest f1-score)\n",
    "      Ex: AUC, Accurary, Precision, Recall, F1-Score.\n",
    "      Then print these metrics\n",
    "      Args:\n",
    "        - ensem_preds: predictions for ids \n",
    "                       :type: a numpy array\n",
    "        - targets: the actual results of ids \n",
    "                   :type: a numpy array                 \n",
    "      Returns:\n",
    "        - None                  \n",
    "    \"\"\"     \n",
    "    best_th = 0\n",
    "    best_score = 0\n",
    "\n",
    "    for th in np.arange(0.0, 0.6, 0.01):\n",
    "        pred = (ensem_preds > th).astype(int)\n",
    "        score = f1_score(targets, pred)\n",
    "        if score > best_score:\n",
    "            best_th = th\n",
    "            best_score = score\n",
    "\n",
    "    print(f\"\\nAUC score: {roc_auc_score(targets, ensem_preds):12.4f}\")\n",
    "    print(f\"Best threshold {best_th:12.4f}\")\n",
    "\n",
    "    preds = (ensem_preds > best_th).astype(int)\n",
    "\n",
    "    cm1 = confusion_matrix(targets, preds)\n",
    "    print('\\nConfusion Matrix : \\n', cm1)\n",
    "    precision, recall, f1 = compute_metrics(cm1)\n",
    "    \n",
    "    print('\\n=============')\n",
    "    print (f'Precision    : {precision:12.4f}')\n",
    "    \n",
    "    print(f'Recall : {recall:12.4f}')\n",
    "    \n",
    "    print(f'F1 Score : {f1:12.4f}')\n",
    "    \n",
    "    total1=sum(sum(cm1))\n",
    "\n",
    "    print('\\n=============')\n",
    "    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "    print (f'Accuracy    : {accuracy1:12.4f}')\n",
    "\n",
    "def get_model(c=1):\n",
    "    model = LinearSVC(C=c, class_weight='balanced', random_state=seed)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " if not os.path.exists(OUTPUT_DIR + 'df_label_covid_5fold.csv'):\n",
    "    folds = df.copy()\n",
    "    Fold = StratifiedKFold(n_splits=fold_num, shuffle=True, random_state=seed)\n",
    "    for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['label_covid'])):\n",
    "        folds.loc[val_index, 'fold'] = int(n)\n",
    "    folds['fold'] = folds['fold'].astype(int)\n",
    "    folds.to_csv(OUTPUT_DIR + 'df_label_covid_5fold.csv', index=False)\n",
    "else:\n",
    "    folds = pd.read_csv(OUTPUT_DIR + 'df_label_covid_5fold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8354910714285715\n",
      "0.796500713373883\n",
      "0.8477509949688369\n",
      "0.7980400991214237\n",
      "0.823946834872719\n",
      "(!) cv5 AUC  0.8203459427530868 0.02029543721070949\n",
      "\n",
      "AUC score:       0.8204\n",
      "Best threshold       0.0000\n",
      "\n",
      "Confusion Matrix : \n",
      " [[810 154]\n",
      " [ 69 277]]\n",
      "\n",
      "=============\n",
      "Precision    :       0.6427\n",
      "Recall :       0.8006\n",
      "F1 Score :       0.7130\n",
      "\n",
      "=============\n",
      "Accuracy    :       0.8298\n"
     ]
    }
   ],
   "source": [
    "y = folds['label_covid']\n",
    "targets = []\n",
    "preds = []\n",
    "aucs = []\n",
    "\n",
    "for fold in range(5):\n",
    "    train_idx = folds['fold'] != fold\n",
    "    valid_idx = folds['fold'] == fold\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_val = X[valid_idx]\n",
    "    y_val = y[valid_idx]\n",
    "\n",
    "    targets.append(y_val)\n",
    "    model = get_model()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_val)\n",
    "    preds.append(pred)\n",
    "    auc = roc_auc_score(y_val, pred)\n",
    "    aucs.append(auc)\n",
    "    print(auc)\n",
    "    del model\n",
    "\n",
    "targets = np.concatenate(targets)\n",
    "preds = np.concatenate(preds)\n",
    "\n",
    "print(\"(!) cv5 AUC \", np.mean(aucs), np.std(aucs))\n",
    "evaluate(preds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " if not os.path.exists(OUTPUT_DIR + 'df_label_abnormal_5fold.csv'):\n",
    "    folds = df.copy()\n",
    "    Fold = StratifiedKFold(n_splits=fold_num, shuffle=True, random_state=seed)\n",
    "    for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['label_abnormal'])):\n",
    "        folds.loc[val_index, 'fold'] = int(n)\n",
    "    folds['fold'] = folds['fold'].astype(int)\n",
    "    folds.to_csv(OUTPUT_DIR + 'df_label_abnormal_5fold.csv', index=False)\n",
    "else:\n",
    "    folds = pd.read_csv(OUTPUT_DIR + 'df_label_abnormal_5fold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7250546704154952\n",
      "0.7641674476726024\n",
      "0.7668853483286473\n",
      "0.7484223680099968\n",
      "0.7917525773195877\n",
      "(!) cv5 AUC  0.7592564823492658 0.02202478303152122\n",
      "\n",
      "AUC score:       0.7593\n",
      "Best threshold       0.0000\n",
      "\n",
      "Confusion Matrix : \n",
      " [[637 188]\n",
      " [123 362]]\n",
      "\n",
      "=============\n",
      "Precision    :       0.6582\n",
      "Recall :       0.7464\n",
      "F1 Score :       0.6995\n",
      "\n",
      "=============\n",
      "Accuracy    :       0.7626\n"
     ]
    }
   ],
   "source": [
    "y = folds['label_abnormal']\n",
    "targets = []\n",
    "preds = []\n",
    "aucs = []\n",
    "\n",
    "for fold in range(5):\n",
    "    train_idx = folds['fold'] != fold\n",
    "    valid_idx = folds['fold'] == fold\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_val = X[valid_idx]\n",
    "    y_val = y[valid_idx]\n",
    "\n",
    "    targets.append(y_val)\n",
    "    model = get_model()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_val)\n",
    "    preds.append(pred)\n",
    "    auc = roc_auc_score(y_val, pred)\n",
    "    aucs.append(auc)\n",
    "    print(auc)\n",
    "    del model\n",
    "\n",
    "targets = np.concatenate(targets)\n",
    "preds = np.concatenate(preds)\n",
    "\n",
    "print(\"(!) cv5 AUC \", np.mean(aucs), np.std(aucs))\n",
    "evaluate(preds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7010309278350515\n"
     ]
    }
   ],
   "source": [
    "y = folds['label_abnormal']\n",
    "pos_scale = (y == 0).sum() / (y == 1).sum()\n",
    "print(pos_scale)\n",
    "\n",
    "def get_model():\n",
    "    model = xgb.XGBClassifier(\n",
    "        max_depth=7,\n",
    "        scale_pos_weight=pos_scale,\n",
    "        learning_rate=0.3,\n",
    "        n_estimators=200,\n",
    "        subsample=1,\n",
    "        colsample_bytree=1,\n",
    "        nthread=-1,\n",
    "        seed=seed,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703186504217432\n",
      "0.7792877225866915\n",
      "0.7659481412058732\n",
      "0.747766323024055\n",
      "0.7513901905654484\n",
      "(!) cv5 AUC  0.7495157763199001 0.025726899810903234\n",
      "\n",
      "AUC score:       0.7495\n",
      "Best threshold       0.0000\n",
      "\n",
      "Confusion Matrix : \n",
      " [[740  85]\n",
      " [193 292]]\n",
      "\n",
      "=============\n",
      "Precision    :       0.7745\n",
      "Recall :       0.6021\n",
      "F1 Score :       0.6775\n",
      "\n",
      "=============\n",
      "Accuracy    :       0.7878\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "preds = []\n",
    "aucs = []\n",
    "\n",
    "for fold in range(5):\n",
    "    train_idx = folds['fold'] != fold\n",
    "    valid_idx = folds['fold'] == fold\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_val = X[valid_idx]\n",
    "    y_val = y[valid_idx]\n",
    "\n",
    "    targets.append(y_val)\n",
    "    model = get_model()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_val)\n",
    "    preds.append(pred)\n",
    "    auc = roc_auc_score(y_val, pred)\n",
    "    aucs.append(auc)\n",
    "    print(auc)\n",
    "    del model\n",
    "\n",
    "targets = np.concatenate(targets)\n",
    "preds = np.concatenate(preds)\n",
    "\n",
    "print(\"(!) cv5 AUC \", np.mean(aucs), np.std(aucs))\n",
    "evaluate(preds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp \"SoundDr_cough.ipynb\" \"$OUTPUT_DIR/SoundDr_cough_frill_svm.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
